### YamlMime:UniversalReference
api_name: []
items:
- children: []
  class: microsoftml_scikit.loss.Exp
  fullName: microsoftml_scikit.loss.Exp
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: microsoftml_scikit.loss
  name: Exp
  source:
    id: Exp
    path: microsoftml_scikit\loss.py
    remote:
      branch: HEAD
      path: microsoftml_scikit\loss.py
      repo: https://apidrop.visualstudio.com/Content%20CI/_git/ReferenceAutomation
    startLine: 8
  summary: "\n**Description**\n\n   Some of the trainers accept a loss parameter that\
    \ will be used for training. It is also known as loss function, objective function,\
    \ or optimization score function.\n\n   Losses can be specified either as a string\
    \ or a loss object. When loss is specified as one of these strings, the default\
    \ values are used for the loss parameters. To change the default parameters, a\
    \ loss object should be used, as seen in examples below.\n\n   Each trainer supports\
    \ only a subset of the losses mentioned above. To get the supported losses and\
    \ the default loss, please refer to the documentation page for the specific trainer.\n\
    \n**Details**\n\n   The [Exponential loss](https://en.wikipedia.org/wiki/Loss_functions_for_classification)\
    \ for classification. Compared to @microsoftml_scikit.loss.Hinge, it penalizes\
    \ more on the wrong prediction and has larger gradients. Its string name is `'exp'`.\n\
    \n   It can be used for @microsoftml_scikit.linear_model.AveragedPerceptronBinaryClassifier,\
    \ @microsoftml_scikit.linear_model.SgdBinaryClassifier.\n\n**See Also**\n\n  \
    \ @microsoftml_scikit.loss.Log, @microsoftml_scikit.loss.Hinge, @microsoftml_scikit.loss.SmoothedHinge,\
    \ @loss-functions\n\n-[ Example ]-\n\n\n\n"
  syntax:
    content: Exp(beta=1.0)
    parameters:
    - description: 'Dilation

        '
      id: beta
  type: class
  uid: microsoftml_scikit.loss.Exp
references: []
