### YamlMime:UniversalReference
api_name: []
items:
- children: []
  class: microsoftml_scikit.linear_model.PoissonRegressionRegressor
  fullName: microsoftml_scikit.linear_model.PoissonRegressionRegressor
  inheritance:
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: microsoftml_scikit.internal.core.base_pipeline_item.BasePipelineItem
    - inheritance:
      - inheritance:
        - inheritance:
          - type: builtins.object
          type: microsoftml_scikit.internal.core.base_pipeline_item.BaseSignature
        type: microsoftml_scikit.internal.core.base_pipeline_item.DefaultSignature
      type: microsoftml_scikit.internal.core.base_pipeline_item.DefaultSignatureWithRoles
    type: microsoftml_scikit.internal.core.linear_model.poissonregressionregressor.PoissonRegressionRegressor
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: sklearn.base.BaseEstimator
    - inheritance:
      - type: builtins.object
      type: microsoftml_scikit.internal.core.base_pipeline_item.BasePipelineItem
    type: microsoftml_scikit.base_predictor.BasePredictor
  - inheritance:
    - type: builtins.object
    type: sklearn.base.RegressorMixin
  langs:
  - python
  module: microsoftml_scikit.linear_model
  name: PoissonRegressionRegressor
  source:
    id: PoissonRegressionRegressor
    path: microsoftml_scikit\linear_model\poissonregressionregressor.py
    remote:
      branch: master
      path: microsoftml_scikit\linear_model\poissonregressionregressor.py
      repo: https://msdata.visualstudio.com/DefaultCollection/AlgorithmsAndDataScience/_git/PyTlc
    startLine: 20
  summary: "**Description**\n   Train an Poisson regression model.\n"
  syntax:
    content: PoissonRegressionRegressor(normalize='Auto', caching='Auto', l2_weight=1.0,
      l1_weight=1.0, opt_tol=1e-07, memory_size=20, enforce_non_negativity=False,
      init_wts_diameter=0.0, max_iterations=2147483647, sgd_init_tol=0.0, quiet=False,
      use_threads=True, train_threads=None, dense_optimizer=False, feature=None, label=None,
      weight=None, columns=None, **params)
    parameters:
    - description: 'see *l-pipeline-syntax*.

        '
      id: feature
    - description: 'see *l-pipeline-syntax*.

        '
      id: label
    - description: 'see *l-pipeline-syntax*.

        '
      id: weight
    - description: 'see *l-pipeline-syntax*.

        '
      id: columns
    - description: 'If `Auto`, the choice to normalize depends on the preference declared
        by the algorithm. This is the

        default choice. If `No`, no normalization is performed. If `Yes`, normalization
        always performed. If `Warn`,

        if normalization is needed by the algorithm, a warning message is displayed
        but normalization is not performed. If

        normalization is performed, a `MaxMin` normalizer is used. This normalizer
        preserves sparsity by mapping zero to

        zero.

        '
      id: normalize
    - description: 'Whether learner should cache input training data.

        '
      id: caching
    - description: 'L2 regularization weight.

        '
      id: l2_weight
    - description: 'L1 regularization weight.

        '
      id: l1_weight
    - description: 'Tolerance parameter for optimization convergence. Lower = slower,
        more accurate.

        '
      id: opt_tol
    - description: 'Memory size for L-BFGS. Lower=faster, less accurate. The technique
        used for optimization here is

        L-BFGS, which uses only a limited amount of memory to compute the next step
        direction. This parameter indicates the

        number of past positions and gradients to store for the computation of the
        next step. Must be greater than or equal

        to `1`.

        '
      id: memory_size
    - description: 'Enforce non-negative weights. This flag, however, does not put
        any constraint on the bias

        term; that is, the bias term can be still a negtaive number.

        '
      id: enforce_non_negativity
    - description: 'Sets the initial weights diameter that specifies the range from
        which values are drawn for the

        initial weights. These weights are initialized randomly from within this range.
        For example, if the diameter is

        specified to be `d`, then the weights are uniformly distributed between `-d/2`
        and `d/2`. The default value is

        `0`, which specifies that all the  weights are set to zero.

        '
      id: init_wts_diameter
    - description: 'Maximum iterations.

        '
      id: max_iterations
    - description: 'Run SGD to initialize LR weights, converging to this tolerance.

        '
      id: sgd_init_tol
    - description: 'If set to true, produce no output during training.

        '
      id: quiet
    - description: 'Whether or not to use threads. Default is true.

        '
      id: use_threads
    - description: 'Number of threads.

        '
      id: train_threads
    - description: 'If `True`, forces densification of the internal optimization vectors.
        If `False`, enables

        the logistic regression optimizer use sparse or dense internal states as it
        finds appropriate. Setting

        `denseOptimizer` to `True` requires the internal optimizer to use a dense
        internal state, which may help

        alleviate load on the garbage collector for some varieties of larger problems.

        '
      id: dense_optimizer
    - description: 'Additional arguments sent to compute engine.

        '
      id: params
  type: class
  uid: microsoftml_scikit.linear_model.PoissonRegressionRegressor
references: []
