### YamlMime:UniversalReference
api_name: []
items:
- children:
  - microsoftml_scikit.FastTreeTweedieRegressor.fit
  - microsoftml_scikit.FastTreeTweedieRegressor.get_params
  - microsoftml_scikit.FastTreeTweedieRegressor.predict
  - microsoftml_scikit.FastTreeTweedieRegressor.score
  - microsoftml_scikit.FastTreeTweedieRegressor.set_params
  class: microsoftml_scikit.FastTreeTweedieRegressor
  fullName: microsoftml_scikit.FastTreeTweedieRegressor
  inheritance:
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: microsoftml_scikit.modules.base.base_pipeline_item.BasePipelineItem
    type: microsoftml_scikit.modules.core.ensemble.fasttreetweedieregressor.FastTreeTweedieRegressor
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: sklearn.base.BaseEstimator
    - inheritance:
      - type: builtins.object
      type: microsoftml_scikit.modules.base.base_pipeline_item.BasePipelineItem
    type: microsoftml_scikit.modules.base.base_predictor.BasePredictor
  - inheritance:
    - type: builtins.object
    type: sklearn.base.RegressorMixin
  langs:
  - python
  module: microsoftml_scikit
  name: FastTreeTweedieRegressor
  source:
    id: FastTreeTweedieRegressor
    path: microsoftml_scikit\modules\ensemble\fasttreetweedieregressor.py
    remote:
      branch: master
      path: microsoftml_scikit\modules\ensemble\fasttreetweedieregressor.py
      repo: https://msdata.visualstudio.com/DefaultCollection/AlgorithmsAndDataScience/_git/PyTlc
    startLine: 20
  summary: '




















    '
  syntax:
    content: 'FastTreeTweedieRegressor(num_trees: numbers.Real = 100, num_leaves:
      numbers.Real = 20, feature_column: str = ''Features'', min_split: numbers.Real
      = 10, label_column: str = ''Label'', learning_rate: numbers.Real = 0.2, weight_column:
      str = None, group_id_column: str = None, normalize: str = ''Auto'', caching:
      str = ''Auto'', index: numbers.Real = 1.5, best_step_ranking_regression_trees:
      bool = False, use_line_search: bool = False, num_post_bracket_steps: numbers.Real
      = 0, min_step_size: numbers.Real = 0.0, optimizer: str = ''GradientDescent'',
      early_stopping_rule: dict = None, early_stopping_metrics: numbers.Real = 0,
      enable_pruning: bool = False, use_tolerant_pruning: bool = False, pruning_threshold:
      numbers.Real = 0.004, pruning_window_size: numbers.Real = 5, shrinkage: numbers.Real
      = 1.0, dropout_rate: numbers.Real = 0.0, get_derivatives_sample_rate: numbers.Real
      = 1, write_last_ensemble: bool = False, max_tree_output: numbers.Real = 100.0,
      random_start: bool = False, filter_zero_lambdas: bool = False, baseline_scores_formula:
      str = None, baseline_alpha_risk: str = None, position_discount_freeform: str
      = None, parallel_trainer: dict = None, train_threads: numbers.Real = None, random_seed:
      numbers.Real = 123, feature_select_seed: numbers.Real = 123, entropy_coefficient:
      numbers.Real = 0.0, histogram_pool_size: numbers.Real = -1, disk_transpose:
      bool = None, feature_flocks: bool = True, num_bins: numbers.Real = 255, sparsify_threshold:
      numbers.Real = 0.7, first_use_penalty: numbers.Real = 0.0, feature_reuse_penalty:
      numbers.Real = 0.0, gain_conf_level: numbers.Real = 0.0, softmax_temperature:
      numbers.Real = 0.0, execution_times: bool = False, feature_fraction: numbers.Real
      = 1.0, bagging_size: numbers.Real = 0, example_fraction: numbers.Real = 0.7,
      split_fraction: numbers.Real = 1.0, smoothing: numbers.Real = 0.0, allow_empty_trees:
      bool = True, feature_compression_level: numbers.Real = 1, compress_ensemble:
      bool = False, max_trees_after_compression: numbers.Real = -1, print_test_graph:
      bool = False, print_train_valid_graph: bool = False, test_frequency: numbers.Real
      = 2147483647, **params)'
    parameters:
    - description: 'Number of weak hypotheses in the ensemble.

        '
      id: num_trees
    - description: 'The max number of leaves in each regression tree.

        '
      id: num_leaves
    - description: 'Column to use for features.

        '
      id: feature_column
    - description: 'The minimal number of documents allowed in a leaf of a regression
        tree, out of the subsampled data.

        '
      id: min_split
    - description: 'Column to use for labels.

        '
      id: label_column
    - description: 'The learning rate.

        '
      id: learning_rate
    - description: 'Column to use for example weight.

        '
      id: weight_column
    - description: 'Column to use for example groupId.

        '
      id: group_id_column
    - description: "Specifies the type of automatic normalization used:\n\n* `\"Auto\"\
        `: if normalization is needed, it is performed automatically. This is the\
        \ default choice. \n\n* `\"No\"`: no normalization is performed. \n\n* `\"\
        Yes\"`: normalization is performed. \n\n* `\"Warn\"`: if normalization is\
        \ needed, a warning message is displayed, but normalization is not performed.\
        \ \n\nNormalization rescales disparate data ranges to a standard scale. Feature\n\
        scaling insures the distances between data points are proportional and\nenables\
        \ various optimization methods such as gradient descent to converge\nmuch\
        \ faster. If normalization is performed, a `MaxMin` normalizer is\nused. It\
        \ normalizes values in an interval [a, b] where `-1 <= a <= 0`\nand `0 <=\
        \ b <= 1` and `b - a = 1`. This normalizer preserves\nsparsity by mapping\
        \ zero to zero.\n"
      id: normalize
    - description: 'Whether learner should cache input training data.

        '
      id: caching
    - description: 'Index parameter for the Tweedie distribution, in the range [1,
        2]. 1 is Poisson loss, 2 is gamma loss, and

        intermediate values are compound Poisson loss.

        '
      id: index
    - description: 'Use best regression step trees?.

        '
      id: best_step_ranking_regression_trees
    - description: 'Should we use line search for a step size.

        '
      id: use_line_search
    - description: 'Number of post-bracket line search steps.

        '
      id: num_post_bracket_steps
    - description: 'Minimum line search step size.

        '
      id: min_step_size
    - description: 'Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent).

        '
      id: optimizer
    - description: 'Early stopping rule. (Validation set (/valid) is required.).

        '
      id: early_stopping_rule
    - description: 'Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking,
        1:NDCG@1, 3:NDCG@3).

        '
      id: early_stopping_metrics
    - description: 'Enable post-training pruning to avoid overfitting. (a validation
        set is required).

        '
      id: enable_pruning
    - description: 'Use window and tolerance for pruning.

        '
      id: use_tolerant_pruning
    - description: 'The tolerance threshold for pruning.

        '
      id: pruning_threshold
    - description: 'The moving window size for pruning.

        '
      id: pruning_window_size
    - description: 'Shrinkage.

        '
      id: shrinkage
    - description: 'Dropout rate for tree regularization.

        '
      id: dropout_rate
    - description: 'Sample each query 1 in k times in the GetDerivatives function.

        '
      id: get_derivatives_sample_rate
    - description: 'Write the last ensemble instead of the one determined by early
        stopping.

        '
      id: write_last_ensemble
    - description: 'Upper bound on absolute value of single tree output.

        '
      id: max_tree_output
    - description: 'Training starts from random ordering (determined by /r1).

        '
      id: random_start
    - description: 'Filter zero lambdas during training.

        '
      id: filter_zero_lambdas
    - description: 'Freeform defining the scores that should be used as the baseline
        ranker.

        '
      id: baseline_scores_formula
    - description: 'Baseline alpha for tradeoffs of risk (0 is normal training).

        '
      id: baseline_alpha_risk
    - description: 'The discount freeform which specifies the per position discounts
        of documents in a

        query (uses a single variable P for position where P=0 is first position).

        '
      id: position_discount_freeform
    - description: 'Allows to choose Parallel FastTree Learning Algorithm.

        '
      id: parallel_trainer
    - description: 'The number of threads to use.

        '
      id: train_threads
    - description: 'The seed of the random number generator.

        '
      id: random_seed
    - description: 'The seed of the active feature selection.

        '
      id: feature_select_seed
    - description: 'The entropy (regularization) coefficient between 0 and 1.

        '
      id: entropy_coefficient
    - description: 'The number of histograms in the pool (between 2 and numLeaves).

        '
      id: histogram_pool_size
    - description: 'Whether to utilize the disk or the data''s native transposition
        facilities (where applicable) when

        performing the transpose.

        '
      id: disk_transpose
    - description: 'Whether to collectivize features during dataset preparation to
        speed up training.

        '
      id: feature_flocks
    - description: 'Maximum number of distinct values (bins) per feature.

        '
      id: num_bins
    - description: 'Sparsity level needed to use sparse feature representation.

        '
      id: sparsify_threshold
    - description: 'The feature first use penalty coefficient.

        '
      id: first_use_penalty
    - description: 'The feature re-use penalty (regularization) coefficient.

        '
      id: feature_reuse_penalty
    - description: 'Tree fitting gain confidence requirement (should be in the range
        [0,1) ).

        '
      id: gain_conf_level
    - description: 'The temperature of the randomized softmax distribution for choosing
        the feature.

        '
      id: softmax_temperature
    - description: 'Print execution time breakdown to stdout.

        '
      id: execution_times
    - description: 'The fraction of features (chosen randomly) to use on each iteration.

        '
      id: feature_fraction
    - description: 'Number of trees in each bag (0 for disabling bagging).

        '
      id: bagging_size
    - description: 'Percentage of training examples used in each bag.

        '
      id: example_fraction
    - description: 'The fraction of features (chosen randomly) to use on each split.

        '
      id: split_fraction
    - description: 'Smoothing paramter for tree regularization.

        '
      id: smoothing
    - description: 'When a root split is impossible, allow training to proceed.

        '
      id: allow_empty_trees
    - description: 'The level of feature compression to use.

        '
      id: feature_compression_level
    - description: 'Compress the tree Ensemble.

        '
      id: compress_ensemble
    - description: 'Maximum Number of trees after compression.

        '
      id: max_trees_after_compression
    - description: 'Print metrics graph for the first test set.

        '
      id: print_test_graph
    - description: 'Print Train and Validation metrics in graph.

        '
      id: print_train_valid_graph
    - description: 'Calculate metric values for train/valid/test every k rounds.

        '
      id: test_frequency
    - description: 'Additional arguments sent to compute engine.

        '
      id: params
  type: class
  uid: microsoftml_scikit.FastTreeTweedieRegressor
- class: microsoftml_scikit.FastTreeTweedieRegressor
  fullName: microsoftml_scikit.FastTreeTweedieRegressor.fit
  langs:
  - python
  module: microsoftml_scikit
  name: fit
  source:
    id: fit
    path: microsoftml_scikit\utils\utils.py
    remote:
      branch: master
      path: microsoftml_scikit\utils\utils.py
      repo: https://msdata.visualstudio.com/DefaultCollection/AlgorithmsAndDataScience/_git/PyTlc
    startLine: 28
  summary: 'Fits the predictor.

    Returns self.

    '
  syntax:
    content: fit(X, y=None, **params)
  type: method
  uid: microsoftml_scikit.FastTreeTweedieRegressor.fit
- class: microsoftml_scikit.FastTreeTweedieRegressor
  fullName: microsoftml_scikit.FastTreeTweedieRegressor.get_params
  langs:
  - python
  module: microsoftml_scikit
  name: get_params
  source:
    id: get_params
    path: sklearn\base.py
    remote:
      branch: master
      path: sklearn\base.py
      repo: https://msdata.visualstudio.com/DefaultCollection/AlgorithmsAndDataScience/_git/PyTlc
    startLine: 213
  summary: 'Get parameters for this estimator.

    '
  syntax:
    content: get_params(deep=True)
    parameters:
    - defaultValue: 'True'
      description: 'If True, will return the parameters for this estimator and

        contained subobjects that are estimators.

        '
      id: deep
      type:
      - boolean, optional
    return:
      description: '**params** -- Parameter names mapped to their values.

        '
      type:
      - mapping of string to any
  type: method
  uid: microsoftml_scikit.FastTreeTweedieRegressor.get_params
- class: microsoftml_scikit.FastTreeTweedieRegressor
  fullName: microsoftml_scikit.FastTreeTweedieRegressor.predict
  langs:
  - python
  module: microsoftml_scikit
  name: predict
  source:
    id: predict
    path: microsoftml_scikit\utils\utils.py
    remote:
      branch: master
      path: microsoftml_scikit\utils\utils.py
      repo: https://msdata.visualstudio.com/DefaultCollection/AlgorithmsAndDataScience/_git/PyTlc
    startLine: 46
  summary: 'Returns predictions.

    '
  syntax:
    content: predict(X, **params)
  type: method
  uid: microsoftml_scikit.FastTreeTweedieRegressor.predict
- class: microsoftml_scikit.FastTreeTweedieRegressor
  fullName: microsoftml_scikit.FastTreeTweedieRegressor.score
  langs:
  - python
  module: microsoftml_scikit
  name: score
  source:
    id: score
    path: sklearn\base.py
    remote:
      branch: master
      path: sklearn\base.py
      repo: https://msdata.visualstudio.com/DefaultCollection/AlgorithmsAndDataScience/_git/PyTlc
    startLine: 357
  summary: 'Returns the coefficient of determination R^2 of the prediction.


    The coefficient R^2 is defined as (1 - u/v), where u is the residual

    sum of squares ((y_true - y_pred) ** 2).sum() and v is the total

    sum of squares ((y_true - y_true.mean()) ** 2).sum().

    The best possible score is 1.0 and it can be negative (because the

    model can be arbitrarily worse). A constant model that always

    predicts the expected value of y, disregarding the input features,

    would get a R^2 score of 0.0.

    '
  syntax:
    content: score(X, y, sample_weight=None)
    parameters:
    - description: 'Test samples.

        '
      id: X
      type:
      - array-like, shape = (n_samples, n_features)
    - description: 'True values for X.

        '
      id: y
      type:
      - array-like, shape = (n_samples)
      - (n_samples, n_outputs)
    - defaultValue: None
      description: 'Sample weights.

        '
      id: sample_weight
      type:
      - array-like, shape = [n_samples], optional
    return:
      description: '**score** -- R^2 of self.predict(X) wrt. y.

        '
      type:
      - float
  type: method
  uid: microsoftml_scikit.FastTreeTweedieRegressor.score
- class: microsoftml_scikit.FastTreeTweedieRegressor
  fullName: microsoftml_scikit.FastTreeTweedieRegressor.set_params
  langs:
  - python
  module: microsoftml_scikit
  name: set_params
  source:
    id: set_params
    path: sklearn\base.py
    remote:
      branch: master
      path: sklearn\base.py
      repo: https://msdata.visualstudio.com/DefaultCollection/AlgorithmsAndDataScience/_git/PyTlc
    startLine: 250
  summary: 'Set the parameters of this estimator.


    The method works on simple estimators as well as on nested objects

    (such as pipelines). The latter have parameters of the form

    `<component>__<parameter>` so that it''s possible to update each

    component of a nested object.

    '
  syntax:
    content: set_params(**params)
    parameters:
    - id: self
    return:
      type:
      - self
  type: method
  uid: microsoftml_scikit.FastTreeTweedieRegressor.set_params
references:
- fullName: microsoftml_scikit.FastTreeTweedieRegressor.fit
  isExternal: false
  name: fit
  parent: microsoftml_scikit.FastTreeTweedieRegressor
  uid: microsoftml_scikit.FastTreeTweedieRegressor.fit
- fullName: microsoftml_scikit.FastTreeTweedieRegressor.get_params
  isExternal: false
  name: get_params
  parent: microsoftml_scikit.FastTreeTweedieRegressor
  uid: microsoftml_scikit.FastTreeTweedieRegressor.get_params
- fullName: microsoftml_scikit.FastTreeTweedieRegressor.predict
  isExternal: false
  name: predict
  parent: microsoftml_scikit.FastTreeTweedieRegressor
  uid: microsoftml_scikit.FastTreeTweedieRegressor.predict
- fullName: microsoftml_scikit.FastTreeTweedieRegressor.score
  isExternal: false
  name: score
  parent: microsoftml_scikit.FastTreeTweedieRegressor
  uid: microsoftml_scikit.FastTreeTweedieRegressor.score
- fullName: microsoftml_scikit.FastTreeTweedieRegressor.set_params
  isExternal: false
  name: set_params
  parent: microsoftml_scikit.FastTreeTweedieRegressor
  uid: microsoftml_scikit.FastTreeTweedieRegressor.set_params
- fullName: boolean, optional
  name: boolean, optional
  spec.python:
  - fullName: boolean
    name: boolean
    uid: boolean
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  uid: boolean, optional
- fullName: array-like, shape = (n_samples, n_features)
  name: array-like, shape = (n_samples, n_features)
  spec.python:
  - fullName: array-like
    name: array-like
    uid: array-like
  - fullName: ', '
    name: ', '
  - fullName: 'shape = '
    name: 'shape = '
    uid: 'shape = '
  - fullName: (
    name: (
  - fullName: n_samples
    name: n_samples
    uid: n_samples
  - fullName: ', '
    name: ', '
  - fullName: n_features
    name: n_features
    uid: n_features
  - fullName: )
    name: )
  uid: array-like, shape = (n_samples, n_features)
- fullName: array-like, shape = (n_samples)
  name: array-like, shape = (n_samples)
  spec.python:
  - fullName: array-like
    name: array-like
    uid: array-like
  - fullName: ', '
    name: ', '
  - fullName: 'shape = '
    name: 'shape = '
    uid: 'shape = '
  - fullName: (
    name: (
  - fullName: n_samples
    name: n_samples
    uid: n_samples
  - fullName: )
    name: )
  uid: array-like, shape = (n_samples)
- fullName: (n_samples, n_outputs)
  name: (n_samples, n_outputs)
  spec.python:
  - fullName: (
    name: (
  - fullName: n_samples
    name: n_samples
    uid: n_samples
  - fullName: ', '
    name: ', '
  - fullName: n_outputs
    name: n_outputs
    uid: n_outputs
  - fullName: )
    name: )
  uid: (n_samples, n_outputs)
- fullName: array-like, shape = [n_samples], optional
  name: array-like, shape = [n_samples], optional
  spec.python:
  - fullName: array-like
    name: array-like
    uid: array-like
  - fullName: ', '
    name: ', '
  - fullName: 'shape = '
    name: 'shape = '
    uid: 'shape = '
  - fullName: '['
    name: '['
  - fullName: n_samples
    name: n_samples
    uid: n_samples
  - fullName: ']'
    name: ']'
  - fullName: ', '
    name: ', '
  - fullName: optional
    name: optional
    uid: optional
  uid: array-like, shape = [n_samples], optional
