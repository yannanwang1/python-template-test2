### YamlMime:UniversalReference
api_name: []
items:
- children:
  - microsoftml_scikit.internal.entrypoints.fasttree_trainbinary.fasttree_trainbinary
  fullName: microsoftml_scikit.internal.entrypoints.fasttree_trainbinary
  langs:
  - python
  module: microsoftml_scikit.internal.entrypoints.fasttree_trainbinary
  name: fasttree_trainbinary
  source:
    id: fasttree_trainbinary
    path: microsoftml_scikit\internal\entrypoints\fasttree_trainbinary.py
    remote:
      branch: master
      path: microsoftml_scikit\internal\entrypoints\fasttree_trainbinary.py
      repo: https://msdata.visualstudio.com/DefaultCollection/AlgorithmsAndDataScience/_git/PyTlc
    startLine: 0
  summary: 'FastTree.TrainBinary

    '
  type: module
  uid: microsoftml_scikit.internal.entrypoints.fasttree_trainbinary
- fullName: microsoftml_scikit.internal.entrypoints.fasttree_trainbinary.fasttree_trainbinary
  langs:
  - python
  module: microsoftml_scikit.internal.entrypoints.fasttree_trainbinary
  name: fasttree_trainbinary
  source:
    id: fasttree_trainbinary
    path: microsoftml_scikit\internal\entrypoints\fasttree_trainbinary.py
    remote:
      branch: master
      path: microsoftml_scikit\internal\entrypoints\fasttree_trainbinary.py
      repo: https://msdata.visualstudio.com/DefaultCollection/AlgorithmsAndDataScience/_git/PyTlc
    startLine: 12
  summary: "**Description**\n   Uses a logit-boost boosted tree learner to perform\
    \ binary classification.\n"
  syntax:
    content: fasttree_trainbinary(training_data, predictor_model=None, num_trees=100,
      num_leaves=20, feature_column='Features', min_documents_in_leafs=10, label_column='Label',
      learning_rates=0.2, weight_column=None, group_id_column=None, normalize_features='Auto',
      caching='Auto', unbalanced_sets=False, best_step_ranking_regression_trees=False,
      use_line_search=False, num_post_bracket_steps=0, min_step_size=0.0, optimization_algorithm='GradientDescent',
      early_stopping_rule=None, early_stopping_metrics=0, enable_pruning=False, use_tolerant_pruning=False,
      pruning_threshold=0.004, pruning_window_size=5, shrinkage=1.0, dropout_rate=0.0,
      get_derivatives_sample_rate=1, write_last_ensemble=False, max_tree_output=100.0,
      random_start=False, filter_zero_lambdas=False, baseline_scores_formula=None,
      baseline_alpha_risk=None, position_discount_freeform=None, parallel_trainer=None,
      num_threads=None, rng_seed=123, feature_select_seed=123, entropy_coefficient=0.0,
      histogram_pool_size=-1, disk_transpose=None, feature_flocks=True, categorical_split=False,
      max_categorical_groups_per_node=64, max_categorical_split_points=64, min_docs_percentage_for_categorical_split=0.001,
      min_docs_for_categorical_split=100, bias=0.0, bundling='None', max_bins=255,
      sparsify_threshold=0.7, feature_first_use_penalty=0.0, feature_reuse_penalty=0.0,
      gain_confidence_level=0.0, softmax_temperature=0.0, execution_times=False, feature_fraction=1.0,
      bagging_size=0, bagging_train_fraction=0.7, split_fraction=1.0, smoothing=0.0,
      allow_empty_trees=True, feature_compression_level=1, compress_ensemble=False,
      max_trees_after_compression=-1, print_test_graph=False, print_train_valid_graph=False,
      test_frequency=2147483647, **params)
    parameters:
    - description: 'Number of weak hypotheses in the ensemble (inputs).

        '
      id: num_trees
    - defaultValue: None
      description: 'The data to be used for training (inputs).

        '
      id: training_data
    - defaultValue: '100'
      description: 'The max number of leaves in each regression tree (inputs).

        '
      id: num_leaves
    - defaultValue: '20'
      description: 'Column to use for features (inputs).

        '
      id: feature_column
    - defaultValue: Features
      description: 'The minimal number of documents allowed in a leaf of a regression
        tree, out of the subsampled data (inputs).

        '
      id: min_documents_in_leafs
    - defaultValue: '10'
      description: 'Column to use for labels (inputs).

        '
      id: label_column
    - defaultValue: Label
      description: 'The learning rate (inputs).

        '
      id: learning_rates
    - defaultValue: '0.2'
      description: 'Column to use for example weight (inputs).

        '
      id: weight_column
    - defaultValue: None
      description: 'Column to use for example groupId (inputs).

        '
      id: group_id_column
    - defaultValue: None
      description: 'Normalize option for the feature column (inputs).

        '
      id: normalize_features
    - defaultValue: Auto
      description: 'Whether learner should cache input training data (inputs).

        '
      id: caching
    - defaultValue: Auto
      description: 'Should we use derivatives optimized for unbalanced sets (inputs).

        '
      id: unbalanced_sets
    - defaultValue: 'False'
      description: 'Use best regression step trees? (inputs).

        '
      id: best_step_ranking_regression_trees
    - defaultValue: 'False'
      description: 'Should we use line search for a step size (inputs).

        '
      id: use_line_search
    - defaultValue: 'False'
      description: 'Number of post-bracket line search steps (inputs).

        '
      id: num_post_bracket_steps
    - defaultValue: '0'
      description: 'Minimum line search step size (inputs).

        '
      id: min_step_size
    - defaultValue: '0.0'
      description: 'Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
        (inputs).

        '
      id: optimization_algorithm
    - defaultValue: GradientDescent
      description: 'Early stopping rule. (Validation set (/valid) is required.) (inputs).

        '
      id: early_stopping_rule
    - defaultValue: None
      description: 'Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking,
        1:NDCG@1, 3:NDCG@3) (inputs).

        '
      id: early_stopping_metrics
    - defaultValue: '0'
      description: 'Enable post-training pruning to avoid overfitting. (a validation
        set is required) (inputs).

        '
      id: enable_pruning
    - defaultValue: 'False'
      description: 'Use window and tolerance for pruning (inputs).

        '
      id: use_tolerant_pruning
    - defaultValue: 'False'
      description: 'The tolerance threshold for pruning (inputs).

        '
      id: pruning_threshold
    - defaultValue: '0.004'
      description: 'The moving window size for pruning (inputs).

        '
      id: pruning_window_size
    - defaultValue: '5'
      description: 'Shrinkage (inputs).

        '
      id: shrinkage
    - defaultValue: '1.0'
      description: 'Dropout rate for tree regularization (inputs).

        '
      id: dropout_rate
    - defaultValue: '0.0'
      description: 'Sample each query 1 in k times in the GetDerivatives function
        (inputs).

        '
      id: get_derivatives_sample_rate
    - defaultValue: '1'
      description: 'Write the last ensemble instead of the one determined by early
        stopping (inputs).

        '
      id: write_last_ensemble
    - defaultValue: 'False'
      description: 'Upper bound on absolute value of single tree output (inputs).

        '
      id: max_tree_output
    - defaultValue: '100.0'
      description: 'Training starts from random ordering (determined by /r1) (inputs).

        '
      id: random_start
    - defaultValue: 'False'
      description: 'Filter zero lambdas during training (inputs).

        '
      id: filter_zero_lambdas
    - defaultValue: 'False'
      description: 'Freeform defining the scores that should be used as the baseline
        ranker (inputs).

        '
      id: baseline_scores_formula
    - defaultValue: None
      description: 'Baseline alpha for tradeoffs of risk (0 is normal training) (inputs).

        '
      id: baseline_alpha_risk
    - defaultValue: None
      description: 'The discount freeform which specifies the per position discounts
        of documents in a query (uses a single variable P for position where P=0 is
        first position) (inputs).

        '
      id: position_discount_freeform
    - defaultValue: None
      description: 'Allows to choose Parallel FastTree Learning Algorithm (inputs).

        '
      id: parallel_trainer
    - defaultValue: None
      description: 'The number of threads to use (inputs).

        '
      id: num_threads
    - defaultValue: None
      description: 'The seed of the random number generator (inputs).

        '
      id: rng_seed
    - defaultValue: '123'
      description: 'The seed of the active feature selection (inputs).

        '
      id: feature_select_seed
    - defaultValue: '123'
      description: 'The entropy (regularization) coefficient between 0 and 1 (inputs).

        '
      id: entropy_coefficient
    - defaultValue: '0.0'
      description: 'The number of histograms in the pool (between 2 and numLeaves)
        (inputs).

        '
      id: histogram_pool_size
    - defaultValue: '-1'
      description: 'Whether to utilize the disk or the data''s native transposition
        facilities (where applicable) when performing the transpose (inputs).

        '
      id: disk_transpose
    - defaultValue: None
      description: 'Whether to collectivize features during dataset preparation to
        speed up training (inputs).

        '
      id: feature_flocks
    - defaultValue: 'True'
      description: 'Whether to do split based on multiple categorical feature values.
        (inputs).

        '
      id: categorical_split
    - defaultValue: 'False'
      description: 'Maximum categorical split groups to consider when splitting on
        a categorical feature. Split groups are a collection of split points. This
        is used to reduce overfitting when there many categorical features. (inputs).

        '
      id: max_categorical_groups_per_node
    - defaultValue: '64'
      description: 'Maximum categorical split points to consider when splitting on
        a categorical feature. (inputs).

        '
      id: max_categorical_split_points
    - defaultValue: '64'
      description: 'Minimum categorical docs percentage in a bin to consider for a
        split. (inputs).

        '
      id: min_docs_percentage_for_categorical_split
    - defaultValue: '0.001'
      description: 'Minimum categorical doc count in a bin to consider for a split.
        (inputs).

        '
      id: min_docs_for_categorical_split
    - defaultValue: '100'
      description: 'Bias for calculating gradient for each feature bin for a categorical
        feature. (inputs).

        '
      id: bias
    - defaultValue: '0.0'
      description: 'Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1):
        Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
        (inputs).

        '
      id: bundling
    - defaultValue: None
      description: 'Maximum number of distinct values (bins) per feature (inputs).

        '
      id: max_bins
    - defaultValue: '255'
      description: 'Sparsity level needed to use sparse feature representation (inputs).

        '
      id: sparsify_threshold
    - defaultValue: '0.7'
      description: 'The feature first use penalty coefficient (inputs).

        '
      id: feature_first_use_penalty
    - defaultValue: '0.0'
      description: 'The feature re-use penalty (regularization) coefficient (inputs).

        '
      id: feature_reuse_penalty
    - defaultValue: '0.0'
      description: 'Tree fitting gain confidence requirement (should be in the range
        [0,1) ). (inputs).

        '
      id: gain_confidence_level
    - defaultValue: '0.0'
      description: 'The temperature of the randomized softmax distribution for choosing
        the feature (inputs).

        '
      id: softmax_temperature
    - defaultValue: '0.0'
      description: 'Print execution time breakdown to stdout (inputs).

        '
      id: execution_times
    - defaultValue: 'False'
      description: 'The fraction of features (chosen randomly) to use on each iteration
        (inputs).

        '
      id: feature_fraction
    - defaultValue: '1.0'
      description: 'Number of trees in each bag (0 for disabling bagging) (inputs).

        '
      id: bagging_size
    - defaultValue: '0'
      description: 'Percentage of training examples used in each bag (inputs).

        '
      id: bagging_train_fraction
    - defaultValue: '0.7'
      description: 'The fraction of features (chosen randomly) to use on each split
        (inputs).

        '
      id: split_fraction
    - defaultValue: '1.0'
      description: 'Smoothing paramter for tree regularization (inputs).

        '
      id: smoothing
    - defaultValue: '0.0'
      description: 'When a root split is impossible, allow training to proceed (inputs).

        '
      id: allow_empty_trees
    - defaultValue: 'True'
      description: 'The level of feature compression to use (inputs).

        '
      id: feature_compression_level
    - defaultValue: '1'
      description: 'Compress the tree Ensemble (inputs).

        '
      id: compress_ensemble
    - defaultValue: 'False'
      description: 'Maximum Number of trees after compression (inputs).

        '
      id: max_trees_after_compression
    - defaultValue: '-1'
      description: 'Print metrics graph for the first test set (inputs).

        '
      id: print_test_graph
    - defaultValue: 'False'
      description: 'Print Train and Validation metrics in graph (inputs).

        '
      id: print_train_valid_graph
    - defaultValue: 'False'
      description: 'Calculate metric values for train/valid/test every k rounds (inputs).

        '
      id: test_frequency
    - defaultValue: '2147483647'
      description: 'The trained model (outputs).

        '
      id: predictor_model
  type: function
  uid: microsoftml_scikit.internal.entrypoints.fasttree_trainbinary.fasttree_trainbinary
references:
- fullName: microsoftml_scikit.internal.entrypoints.fasttree_trainbinary.fasttree_trainbinary
  isExternal: false
  name: fasttree_trainbinary
  parent: microsoftml_scikit.internal.entrypoints.fasttree_trainbinary
  uid: microsoftml_scikit.internal.entrypoints.fasttree_trainbinary.fasttree_trainbinary
